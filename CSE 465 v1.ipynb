{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba6590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916c571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62369e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os \n",
    "import time\n",
    "#import cv2\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "#import matplotlib.pyplot as plt\n",
    "#from tqdm import tqdm\n",
    "from keras.utils import np_utils\n",
    "#from imgaug import augmenters as iaa    \n",
    "import itertools\n",
    "%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import CSVLogger\n",
    "#from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "#from classification_models.keras import Classifiers\n",
    "# GPU test\n",
    "from tensorflow.python.client import device_lib\n",
    "np.random.seed(42)\n",
    "from keras.models import load_model\n",
    "# Print version\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.regularizers import l2\n",
    "import os, sys\n",
    "import scipy.misc\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import random \n",
    "import shutil \n",
    "import keras\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPool2D, Activation,Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ce9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:/Users/Havoc/OneDrive/Documents/chest_xray/chest_xray/train\"\n",
    "valid_dir = \"C:/Users/Havoc/OneDrive/Documents/chest_xray/chest_xray/val\"\n",
    "\n",
    "img_width, img_height = 224, 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce7a0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "51879936/51877672 [==============================] - 21s 0us/step\n",
      "51888128/51877672 [==============================] - 21s 0us/step\n",
      "Model: \"densenet169\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
      " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
      " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
      " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
      " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
      " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
      " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
      " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
      " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
      " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
      " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
      " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
      " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
      " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
      " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
      " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
      " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
      " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
      " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
      " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
      " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
      " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
      " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
      " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
      " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
      " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
      " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
      " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
      " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
      " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
      " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
      " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
      " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
      " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
      " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
      " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
      " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
      " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
      " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
      " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
      " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
      " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block25_0_bn (BatchNorma  (None, 14, 14, 1024  4096       ['conv4_block24_concat[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block25_0_relu (Activati  (None, 14, 14, 1024  0          ['conv4_block25_0_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block25_1_conv (Conv2D)  (None, 14, 14, 128)  131072      ['conv4_block25_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block25_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block25_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block25_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block25_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block25_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block25_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block25_concat (Concaten  (None, 14, 14, 1056  0          ['conv4_block24_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block25_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block26_0_bn (BatchNorma  (None, 14, 14, 1056  4224       ['conv4_block25_concat[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block26_0_relu (Activati  (None, 14, 14, 1056  0          ['conv4_block26_0_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block26_1_conv (Conv2D)  (None, 14, 14, 128)  135168      ['conv4_block26_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block26_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block26_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block26_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block26_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block26_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block26_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block26_concat (Concaten  (None, 14, 14, 1088  0          ['conv4_block25_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block26_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block27_0_bn (BatchNorma  (None, 14, 14, 1088  4352       ['conv4_block26_concat[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block27_0_relu (Activati  (None, 14, 14, 1088  0          ['conv4_block27_0_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block27_1_conv (Conv2D)  (None, 14, 14, 128)  139264      ['conv4_block27_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block27_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block27_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block27_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block27_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block27_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block27_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block27_concat (Concaten  (None, 14, 14, 1120  0          ['conv4_block26_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block27_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block28_0_bn (BatchNorma  (None, 14, 14, 1120  4480       ['conv4_block27_concat[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block28_0_relu (Activati  (None, 14, 14, 1120  0          ['conv4_block28_0_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block28_1_conv (Conv2D)  (None, 14, 14, 128)  143360      ['conv4_block28_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block28_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block28_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block28_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block28_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block28_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block28_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block28_concat (Concaten  (None, 14, 14, 1152  0          ['conv4_block27_concat[0][0]',   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ate)                           )                                 'conv4_block28_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block29_0_bn (BatchNorma  (None, 14, 14, 1152  4608       ['conv4_block28_concat[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block29_0_relu (Activati  (None, 14, 14, 1152  0          ['conv4_block29_0_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block29_1_conv (Conv2D)  (None, 14, 14, 128)  147456      ['conv4_block29_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block29_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block29_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block29_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block29_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block29_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block29_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block29_concat (Concaten  (None, 14, 14, 1184  0          ['conv4_block28_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block29_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block30_0_bn (BatchNorma  (None, 14, 14, 1184  4736       ['conv4_block29_concat[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block30_0_relu (Activati  (None, 14, 14, 1184  0          ['conv4_block30_0_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block30_1_conv (Conv2D)  (None, 14, 14, 128)  151552      ['conv4_block30_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block30_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block30_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block30_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block30_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block30_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block30_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block30_concat (Concaten  (None, 14, 14, 1216  0          ['conv4_block29_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block30_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block31_0_bn (BatchNorma  (None, 14, 14, 1216  4864       ['conv4_block30_concat[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block31_0_relu (Activati  (None, 14, 14, 1216  0          ['conv4_block31_0_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block31_1_conv (Conv2D)  (None, 14, 14, 128)  155648      ['conv4_block31_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block31_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block31_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block31_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block31_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block31_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block31_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block31_concat (Concaten  (None, 14, 14, 1248  0          ['conv4_block30_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block31_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block32_0_bn (BatchNorma  (None, 14, 14, 1248  4992       ['conv4_block31_concat[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block32_0_relu (Activati  (None, 14, 14, 1248  0          ['conv4_block32_0_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block32_1_conv (Conv2D)  (None, 14, 14, 128)  159744      ['conv4_block32_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block32_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block32_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block32_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block32_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block32_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block32_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block32_concat (Concaten  (None, 14, 14, 1280  0          ['conv4_block31_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block32_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_bn (BatchNormalization)  (None, 14, 14, 1280  5120        ['conv4_block32_concat[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool4_relu (Activation)        (None, 14, 14, 1280  0           ['pool4_bn[0][0]']               \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " pool4_conv (Conv2D)            (None, 14, 14, 640)  819200      ['pool4_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool4_pool (AveragePooling2D)  (None, 7, 7, 640)    0           ['pool4_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['pool4_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_concat (Concatena  (None, 7, 7, 672)   0           ['pool4_pool[0][0]',             \n",
      " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block1_concat[0][0]',    \n",
      " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block2_concat[0][0]',    \n",
      " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block3_concat[0][0]',    \n",
      " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv5_block5_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block4_concat[0][0]',    \n",
      " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 800)   3200        ['conv5_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_0_relu (Activatio  (None, 7, 7, 800)   0           ['conv5_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    102400      ['conv5_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_concat (Concatena  (None, 7, 7, 832)   0           ['conv5_block5_concat[0][0]',    \n",
      " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 832)   3328        ['conv5_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_0_relu (Activatio  (None, 7, 7, 832)   0           ['conv5_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    106496      ['conv5_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_concat (Concatena  (None, 7, 7, 864)   0           ['conv5_block6_concat[0][0]',    \n",
      " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 864)   3456        ['conv5_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_0_relu (Activatio  (None, 7, 7, 864)   0           ['conv5_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    110592      ['conv5_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_concat (Concatena  (None, 7, 7, 896)   0           ['conv5_block7_concat[0][0]',    \n",
      " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 896)   3584        ['conv5_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_0_relu (Activatio  (None, 7, 7, 896)   0           ['conv5_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    114688      ['conv5_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_concat (Concatena  (None, 7, 7, 928)   0           ['conv5_block8_concat[0][0]',    \n",
      " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block9_concat[0][0]',    \n",
      " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block10_concat[0][0]',   \n",
      " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block11_concat[0][0]',   \n",
      " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 1024)  4096        ['conv5_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_0_relu (Activati  (None, 7, 7, 1024)  0           ['conv5_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    131072      ['conv5_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block13_concat (Concaten  (None, 7, 7, 1056)  0           ['conv5_block12_concat[0][0]',   \n",
      " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 1056)  4224        ['conv5_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_0_relu (Activati  (None, 7, 7, 1056)  0           ['conv5_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    135168      ['conv5_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_concat (Concaten  (None, 7, 7, 1088)  0           ['conv5_block13_concat[0][0]',   \n",
      " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 1088)  4352        ['conv5_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_0_relu (Activati  (None, 7, 7, 1088)  0           ['conv5_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    139264      ['conv5_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_concat (Concaten  (None, 7, 7, 1120)  0           ['conv5_block14_concat[0][0]',   \n",
      " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 1120)  4480        ['conv5_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_0_relu (Activati  (None, 7, 7, 1120)  0           ['conv5_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    143360      ['conv5_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_concat (Concaten  (None, 7, 7, 1152)  0           ['conv5_block15_concat[0][0]',   \n",
      " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block17_0_bn (BatchNorma  (None, 7, 7, 1152)  4608        ['conv5_block16_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block17_0_relu (Activati  (None, 7, 7, 1152)  0           ['conv5_block17_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block17_1_conv (Conv2D)  (None, 7, 7, 128)    147456      ['conv5_block17_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block17_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block17_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block17_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block17_concat (Concaten  (None, 7, 7, 1184)  0           ['conv5_block16_concat[0][0]',   \n",
      " ate)                                                             'conv5_block17_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block18_0_bn (BatchNorma  (None, 7, 7, 1184)  4736        ['conv5_block17_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block18_0_relu (Activati  (None, 7, 7, 1184)  0           ['conv5_block18_0_bn[0][0]']     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block18_1_conv (Conv2D)  (None, 7, 7, 128)    151552      ['conv5_block18_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block18_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block18_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block18_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block18_concat (Concaten  (None, 7, 7, 1216)  0           ['conv5_block17_concat[0][0]',   \n",
      " ate)                                                             'conv5_block18_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block19_0_bn (BatchNorma  (None, 7, 7, 1216)  4864        ['conv5_block18_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block19_0_relu (Activati  (None, 7, 7, 1216)  0           ['conv5_block19_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block19_1_conv (Conv2D)  (None, 7, 7, 128)    155648      ['conv5_block19_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block19_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block19_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block19_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block19_concat (Concaten  (None, 7, 7, 1248)  0           ['conv5_block18_concat[0][0]',   \n",
      " ate)                                                             'conv5_block19_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block20_0_bn (BatchNorma  (None, 7, 7, 1248)  4992        ['conv5_block19_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block20_0_relu (Activati  (None, 7, 7, 1248)  0           ['conv5_block20_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block20_1_conv (Conv2D)  (None, 7, 7, 128)    159744      ['conv5_block20_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block20_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block20_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block20_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block20_concat (Concaten  (None, 7, 7, 1280)  0           ['conv5_block19_concat[0][0]',   \n",
      " ate)                                                             'conv5_block20_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block21_0_bn (BatchNorma  (None, 7, 7, 1280)  5120        ['conv5_block20_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block21_0_relu (Activati  (None, 7, 7, 1280)  0           ['conv5_block21_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block21_1_conv (Conv2D)  (None, 7, 7, 128)    163840      ['conv5_block21_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block21_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block21_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block21_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block21_concat (Concaten  (None, 7, 7, 1312)  0           ['conv5_block20_concat[0][0]',   \n",
      " ate)                                                             'conv5_block21_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block22_0_bn (BatchNorma  (None, 7, 7, 1312)  5248        ['conv5_block21_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block22_0_relu (Activati  (None, 7, 7, 1312)  0           ['conv5_block22_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block22_1_conv (Conv2D)  (None, 7, 7, 128)    167936      ['conv5_block22_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block22_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block22_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block22_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block22_concat (Concaten  (None, 7, 7, 1344)  0           ['conv5_block21_concat[0][0]',   \n",
      " ate)                                                             'conv5_block22_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block23_0_bn (BatchNorma  (None, 7, 7, 1344)  5376        ['conv5_block22_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block23_0_relu (Activati  (None, 7, 7, 1344)  0           ['conv5_block23_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block23_1_conv (Conv2D)  (None, 7, 7, 128)    172032      ['conv5_block23_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block23_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block23_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block23_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block23_concat (Concaten  (None, 7, 7, 1376)  0           ['conv5_block22_concat[0][0]',   \n",
      " ate)                                                             'conv5_block23_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block24_0_bn (BatchNorma  (None, 7, 7, 1376)  5504        ['conv5_block23_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block24_0_relu (Activati  (None, 7, 7, 1376)  0           ['conv5_block24_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block24_1_conv (Conv2D)  (None, 7, 7, 128)    176128      ['conv5_block24_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block24_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block24_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block24_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block24_concat (Concaten  (None, 7, 7, 1408)  0           ['conv5_block23_concat[0][0]',   \n",
      " ate)                                                             'conv5_block24_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block25_0_bn (BatchNorma  (None, 7, 7, 1408)  5632        ['conv5_block24_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block25_0_relu (Activati  (None, 7, 7, 1408)  0           ['conv5_block25_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block25_1_conv (Conv2D)  (None, 7, 7, 128)    180224      ['conv5_block25_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block25_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block25_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block25_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block25_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block25_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block25_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block25_concat (Concaten  (None, 7, 7, 1440)  0           ['conv5_block24_concat[0][0]',   \n",
      " ate)                                                             'conv5_block25_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block26_0_bn (BatchNorma  (None, 7, 7, 1440)  5760        ['conv5_block25_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block26_0_relu (Activati  (None, 7, 7, 1440)  0           ['conv5_block26_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block26_1_conv (Conv2D)  (None, 7, 7, 128)    184320      ['conv5_block26_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block26_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block26_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block26_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block26_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block26_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block26_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block26_concat (Concaten  (None, 7, 7, 1472)  0           ['conv5_block25_concat[0][0]',   \n",
      " ate)                                                             'conv5_block26_2_conv[0][0]']   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv5_block27_0_bn (BatchNorma  (None, 7, 7, 1472)  5888        ['conv5_block26_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block27_0_relu (Activati  (None, 7, 7, 1472)  0           ['conv5_block27_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block27_1_conv (Conv2D)  (None, 7, 7, 128)    188416      ['conv5_block27_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block27_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block27_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block27_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block27_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block27_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block27_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block27_concat (Concaten  (None, 7, 7, 1504)  0           ['conv5_block26_concat[0][0]',   \n",
      " ate)                                                             'conv5_block27_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block28_0_bn (BatchNorma  (None, 7, 7, 1504)  6016        ['conv5_block27_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block28_0_relu (Activati  (None, 7, 7, 1504)  0           ['conv5_block28_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block28_1_conv (Conv2D)  (None, 7, 7, 128)    192512      ['conv5_block28_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block28_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block28_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block28_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block28_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block28_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block28_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block28_concat (Concaten  (None, 7, 7, 1536)  0           ['conv5_block27_concat[0][0]',   \n",
      " ate)                                                             'conv5_block28_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block29_0_bn (BatchNorma  (None, 7, 7, 1536)  6144        ['conv5_block28_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block29_0_relu (Activati  (None, 7, 7, 1536)  0           ['conv5_block29_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block29_1_conv (Conv2D)  (None, 7, 7, 128)    196608      ['conv5_block29_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block29_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block29_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block29_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block29_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block29_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block29_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block29_concat (Concaten  (None, 7, 7, 1568)  0           ['conv5_block28_concat[0][0]',   \n",
      " ate)                                                             'conv5_block29_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block30_0_bn (BatchNorma  (None, 7, 7, 1568)  6272        ['conv5_block29_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block30_0_relu (Activati  (None, 7, 7, 1568)  0           ['conv5_block30_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block30_1_conv (Conv2D)  (None, 7, 7, 128)    200704      ['conv5_block30_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block30_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block30_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block30_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block30_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block30_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block30_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block30_concat (Concaten  (None, 7, 7, 1600)  0           ['conv5_block29_concat[0][0]',   \n",
      " ate)                                                             'conv5_block30_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block31_0_bn (BatchNorma  (None, 7, 7, 1600)  6400        ['conv5_block30_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block31_0_relu (Activati  (None, 7, 7, 1600)  0           ['conv5_block31_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block31_1_conv (Conv2D)  (None, 7, 7, 128)    204800      ['conv5_block31_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block31_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block31_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block31_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block31_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block31_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block31_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block31_concat (Concaten  (None, 7, 7, 1632)  0           ['conv5_block30_concat[0][0]',   \n",
      " ate)                                                             'conv5_block31_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block32_0_bn (BatchNorma  (None, 7, 7, 1632)  6528        ['conv5_block31_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block32_0_relu (Activati  (None, 7, 7, 1632)  0           ['conv5_block32_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block32_1_conv (Conv2D)  (None, 7, 7, 128)    208896      ['conv5_block32_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block32_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block32_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block32_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block32_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block32_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block32_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block32_concat (Concaten  (None, 7, 7, 1664)  0           ['conv5_block31_concat[0][0]',   \n",
      " ate)                                                             'conv5_block32_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " bn (BatchNormalization)        (None, 7, 7, 1664)   6656        ['conv5_block32_concat[0][0]']   \n",
      "                                                                                                  \n",
      " relu (Activation)              (None, 7, 7, 1664)   0           ['bn[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,642,880\n",
      "Trainable params: 12,484,480\n",
      "Non-trainable params: 158,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = tf.keras.applications.DenseNet169(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(img_width, img_height, 3),\n",
    ")\n",
    "\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37319c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1227 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 7, 7, 1664)) # Must be equal to the output of the convolutional base\n",
    "    labels = np.zeros(shape=(sample_count,2))\n",
    "    # Preprocess data\n",
    "    generator = datagen.flow_from_directory(directory,\n",
    "                                            target_size=(img_width,img_height),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode='categorical')\n",
    " \n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "train_features, train_labels = extract_features(train_dir, 1227) \n",
    "validation_features, validation_labels = extract_features(valid_dir, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a114f211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1227, 7, 7, 1664)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5609f375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 7, 7, 1664)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a79711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd4f8746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " global_average_pooling2d (G  (None, 1664)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 3330      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,330\n",
      "Trainable params: 3,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GlobalAveragePooling2D(input_shape=(7, 7, 1664)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c215789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.2589 - acc: 0.9193\n",
      "Epoch 1: val_loss improved from inf to 0.84667, saving model to model-001-0.920130-0.500000.h5\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2532 - acc: 0.9201 - val_loss: 0.8467 - val_acc: 0.5000\n",
      "Epoch 2/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.1140 - acc: 0.9510\n",
      "Epoch 2: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.1116 - acc: 0.9527 - val_loss: 0.9552 - val_acc: 0.5000\n",
      "Epoch 3/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0694 - acc: 0.9738\n",
      "Epoch 3: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0720 - acc: 0.9731 - val_loss: 1.2130 - val_acc: 0.5000\n",
      "Epoch 4/150\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0498 - acc: 0.9893\n",
      "Epoch 4: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0542 - acc: 0.9853 - val_loss: 1.2340 - val_acc: 0.5000\n",
      "Epoch 5/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0422 - acc: 0.9934\n",
      "Epoch 5: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0425 - acc: 0.9935 - val_loss: 1.4482 - val_acc: 0.5000\n",
      "Epoch 6/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0367 - acc: 0.9936\n",
      "Epoch 6: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0351 - acc: 0.9943 - val_loss: 1.5399 - val_acc: 0.5000\n",
      "Epoch 7/150\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.0252 - acc: 0.9953\n",
      "Epoch 7: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0295 - acc: 0.9959 - val_loss: 1.2519 - val_acc: 0.5625\n",
      "Epoch 8/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9975\n",
      "Epoch 8: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0253 - acc: 0.9976 - val_loss: 1.2836 - val_acc: 0.5625\n",
      "Epoch 9/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0228 - acc: 0.9957\n",
      "Epoch 9: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0229 - acc: 0.9959 - val_loss: 1.6427 - val_acc: 0.5000\n",
      "Epoch 10/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0209 - acc: 0.9974\n",
      "Epoch 10: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0202 - acc: 0.9976 - val_loss: 1.7243 - val_acc: 0.5000\n",
      "Epoch 11/150\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0187 - acc: 0.9990\n",
      "Epoch 11: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0179 - acc: 0.9992 - val_loss: 1.6607 - val_acc: 0.5000\n",
      "Epoch 12/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0163 - acc: 0.9982\n",
      "Epoch 12: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0161 - acc: 0.9984 - val_loss: 1.7537 - val_acc: 0.5000\n",
      "Epoch 13/150\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.0156 - acc: 0.9984\n",
      "Epoch 13: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0145 - acc: 0.9992 - val_loss: 1.4944 - val_acc: 0.5625\n",
      "Epoch 14/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9992\n",
      "Epoch 14: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0137 - acc: 0.9992 - val_loss: 1.6568 - val_acc: 0.5000\n",
      "Epoch 15/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0130 - acc: 0.9991\n",
      "Epoch 15: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0127 - acc: 0.9992 - val_loss: 1.8076 - val_acc: 0.5000\n",
      "Epoch 16/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 16: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0114 - acc: 0.9992 - val_loss: 1.6259 - val_acc: 0.5000\n",
      "Epoch 17/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 17: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0108 - acc: 0.9992 - val_loss: 1.6680 - val_acc: 0.5000\n",
      "Epoch 18/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0109 - acc: 0.9991\n",
      "Epoch 18: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0107 - acc: 0.9992 - val_loss: 1.8154 - val_acc: 0.5000\n",
      "Epoch 19/150\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.0086 - acc: 0.9990\n",
      "Epoch 19: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0086 - acc: 0.9992 - val_loss: 1.9939 - val_acc: 0.5000\n",
      "Epoch 20/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0083 - acc: 0.9991\n",
      "Epoch 20: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0085 - acc: 0.9992 - val_loss: 1.8703 - val_acc: 0.5000\n",
      "Epoch 21/150\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 21: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 1.7911 - val_acc: 0.5000\n",
      "Epoch 22/150\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 22: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.2141 - val_acc: 0.5000\n",
      "Epoch 23/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 23: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.1954 - val_acc: 0.5000\n",
      "Epoch 24/150\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 24: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0069 - acc: 0.9992 - val_loss: 2.0929 - val_acc: 0.5000\n",
      "Epoch 25/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 25: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.9778 - val_acc: 0.5000\n",
      "Epoch 26/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.0058 - acc: 0.9991\n",
      "Epoch 26: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0059 - acc: 0.9992 - val_loss: 1.8420 - val_acc: 0.5000\n",
      "Epoch 27/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0052 - acc: 0.9991\n",
      "Epoch 27: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0054 - acc: 0.9992 - val_loss: 1.8839 - val_acc: 0.5000\n",
      "Epoch 28/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 28: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.0847 - val_acc: 0.5000\n",
      "Epoch 29/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 29: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.2184 - val_acc: 0.5000\n",
      "Epoch 30/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 30: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.1194 - val_acc: 0.5000\n",
      "Epoch 31/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 31: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.2744 - val_acc: 0.5000\n",
      "Epoch 32/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 32: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.0713 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 33: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.2687 - val_acc: 0.5000\n",
      "Epoch 34/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 34: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.2233 - val_acc: 0.5000\n",
      "Epoch 35/150\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 35: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.2485 - val_acc: 0.5000\n",
      "Epoch 36/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 2.2301 - val_acc: 0.5000\n",
      "Epoch 37/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 2.2009 - val_acc: 0.5000\n",
      "Epoch 38/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0032 - acc: 1.0000   \n",
      "Epoch 38: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 2.3450 - val_acc: 0.5000\n",
      "Epoch 39/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.3654 - val_acc: 0.5000\n",
      "Epoch 40/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.4491 - val_acc: 0.5000\n",
      "Epoch 41/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 2.4022 - val_acc: 0.5000\n",
      "Epoch 42/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.4395 - val_acc: 0.5000\n",
      "Epoch 43/150\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.4860 - val_acc: 0.5000\n",
      "Epoch 44/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 2.4617 - val_acc: 0.5000\n",
      "Epoch 45/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.3959 - val_acc: 0.5000\n",
      "Epoch 46/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 46: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.4383 - val_acc: 0.5000\n",
      "Epoch 47/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.4106 - val_acc: 0.5000\n",
      "Epoch 48/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.4946 - val_acc: 0.5000\n",
      "Epoch 49/150\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 49: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.6143 - val_acc: 0.5000\n",
      "Epoch 50/150\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0022 - acc: 1.0000   \n",
      "Epoch 50: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.5549 - val_acc: 0.5000\n",
      "Epoch 51/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 51: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.5068 - val_acc: 0.5000\n",
      "Epoch 52/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 52: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.4353 - val_acc: 0.5000\n",
      "Epoch 53/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 53: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.5877 - val_acc: 0.5000\n",
      "Epoch 54/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 1.0000   \n",
      "Epoch 54: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.6324 - val_acc: 0.5000\n",
      "Epoch 55/150\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 55: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.5492 - val_acc: 0.5000\n",
      "Epoch 56/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.0017 - acc: 1.0000   \n",
      "Epoch 56: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.5316 - val_acc: 0.5000\n",
      "Epoch 57/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0015 - acc: 1.0000   \n",
      "Epoch 57: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.5149 - val_acc: 0.5000\n",
      "Epoch 58/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 58: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.8311 - val_acc: 0.5000\n",
      "Epoch 59/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0015 - acc: 1.0000   \n",
      "Epoch 59: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.6257 - val_acc: 0.5000\n",
      "Epoch 60/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 1.0000   \n",
      "Epoch 60: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.5678 - val_acc: 0.5000\n",
      "Epoch 61/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 61: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.7372 - val_acc: 0.5000\n",
      "Epoch 62/150\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 62: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.7552 - val_acc: 0.5000\n",
      "Epoch 63/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0013 - acc: 1.0000    \n",
      "Epoch 63: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.5488 - val_acc: 0.5000\n",
      "Epoch 64/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0013 - acc: 1.0000   \n",
      "Epoch 64: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.5406 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 65: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.7773 - val_acc: 0.5000\n",
      "Epoch 66/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 1.0000   \n",
      "Epoch 66: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.7525 - val_acc: 0.5000\n",
      "Epoch 67/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 67: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.8878 - val_acc: 0.5000\n",
      "Epoch 68/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0011 - acc: 1.0000   \n",
      "Epoch 68: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.7016 - val_acc: 0.5000\n",
      "Epoch 69/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 69: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.8333 - val_acc: 0.5000\n",
      "Epoch 70/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 70: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.7358 - val_acc: 0.5000\n",
      "Epoch 71/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0010 - acc: 1.0000    \n",
      "Epoch 71: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.7865 - val_acc: 0.5000\n",
      "Epoch 72/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0011 - acc: 1.0000   \n",
      "Epoch 72: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.8041 - val_acc: 0.5000\n",
      "Epoch 73/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 9.9120e-04 - acc: 1.0000\n",
      "Epoch 73: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 9.9120e-04 - acc: 1.0000 - val_loss: 2.7766 - val_acc: 0.5000\n",
      "Epoch 74/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 9.9192e-04 - acc: 1.0000\n",
      "Epoch 74: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 9.7530e-04 - acc: 1.0000 - val_loss: 2.7598 - val_acc: 0.5000\n",
      "Epoch 75/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 9.5674e-04 - acc: 1.0000\n",
      "Epoch 75: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 9.7806e-04 - acc: 1.0000 - val_loss: 2.7663 - val_acc: 0.5000\n",
      "Epoch 76/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 9.8261e-04 - acc: 1.0000\n",
      "Epoch 76: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 9.3305e-04 - acc: 1.0000 - val_loss: 2.8022 - val_acc: 0.5000\n",
      "Epoch 77/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 9.1556e-04 - acc: 1.0000\n",
      "Epoch 77: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 8.9570e-04 - acc: 1.0000 - val_loss: 2.8612 - val_acc: 0.5000\n",
      "Epoch 78/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 8.7855e-04 - acc: 1.0000\n",
      "Epoch 78: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 8.6897e-04 - acc: 1.0000 - val_loss: 2.9363 - val_acc: 0.5000\n",
      "Epoch 79/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 8.7291e-04 - acc: 1.0000\n",
      "Epoch 79: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 8.5586e-04 - acc: 1.0000 - val_loss: 2.9720 - val_acc: 0.5000\n",
      "Epoch 80/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 8.3190e-04 - acc: 1.0000\n",
      "Epoch 80: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 8.2532e-04 - acc: 1.0000 - val_loss: 2.7999 - val_acc: 0.5000\n",
      "Epoch 81/150\n",
      "21/39 [===============>..............] - ETA: 0s - loss: 7.0473e-04 - acc: 1.0000\n",
      "Epoch 81: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 7.9817e-04 - acc: 1.0000 - val_loss: 2.8998 - val_acc: 0.5000\n",
      "Epoch 82/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 7.9103e-04 - acc: 1.0000\n",
      "Epoch 82: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 7.9103e-04 - acc: 1.0000 - val_loss: 2.8173 - val_acc: 0.5000\n",
      "Epoch 83/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 7.4950e-04 - acc: 1.0000\n",
      "Epoch 83: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 7.5184e-04 - acc: 1.0000 - val_loss: 2.9903 - val_acc: 0.5000\n",
      "Epoch 84/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 7.8426e-04 - acc: 1.0000\n",
      "Epoch 84: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 7.7766e-04 - acc: 1.0000 - val_loss: 3.1033 - val_acc: 0.5000\n",
      "Epoch 85/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 7.8360e-04 - acc: 1.0000\n",
      "Epoch 85: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 7.3742e-04 - acc: 1.0000 - val_loss: 2.8756 - val_acc: 0.5000\n",
      "Epoch 86/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 6.7766e-04 - acc: 1.0000\n",
      "Epoch 86: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 7.1156e-04 - acc: 1.0000 - val_loss: 2.9863 - val_acc: 0.5000\n",
      "Epoch 87/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 7.0696e-04 - acc: 1.0000\n",
      "Epoch 87: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 7.0618e-04 - acc: 1.0000 - val_loss: 3.0470 - val_acc: 0.5000\n",
      "Epoch 88/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 6.7786e-04 - acc: 1.0000\n",
      "Epoch 88: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 6.7750e-04 - acc: 1.0000 - val_loss: 2.8956 - val_acc: 0.5000\n",
      "Epoch 89/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 6.7177e-04 - acc: 1.0000\n",
      "Epoch 89: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 6.5019e-04 - acc: 1.0000 - val_loss: 2.9749 - val_acc: 0.5000\n",
      "Epoch 90/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 6.3553e-04 - acc: 1.0000\n",
      "Epoch 90: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 6.3609e-04 - acc: 1.0000 - val_loss: 2.9501 - val_acc: 0.5000\n",
      "Epoch 91/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 6.5796e-04 - acc: 1.0000\n",
      "Epoch 91: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 6.3170e-04 - acc: 1.0000 - val_loss: 2.9374 - val_acc: 0.5000\n",
      "Epoch 92/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 5.9098e-04 - acc: 1.0000\n",
      "Epoch 92: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 6.1675e-04 - acc: 1.0000 - val_loss: 2.9897 - val_acc: 0.5000\n",
      "Epoch 93/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 6.0949e-04 - acc: 1.0000\n",
      "Epoch 93: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 6.0821e-04 - acc: 1.0000 - val_loss: 3.0853 - val_acc: 0.5000\n",
      "Epoch 94/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 5.5116e-04 - acc: 1.0000\n",
      "Epoch 94: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 5.8096e-04 - acc: 1.0000 - val_loss: 2.9900 - val_acc: 0.5000\n",
      "Epoch 95/150\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 5.4188e-04 - acc: 1.0000\n",
      "Epoch 95: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 5.7040e-04 - acc: 1.0000 - val_loss: 2.9961 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 6.0153e-04 - acc: 1.0000\n",
      "Epoch 96: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 6.0153e-04 - acc: 1.0000 - val_loss: 2.9102 - val_acc: 0.5000\n",
      "Epoch 97/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 5.3567e-04 - acc: 1.0000\n",
      "Epoch 97: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 5.3110e-04 - acc: 1.0000 - val_loss: 3.1131 - val_acc: 0.5000\n",
      "Epoch 98/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 5.5011e-04 - acc: 1.0000\n",
      "Epoch 98: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 5.3828e-04 - acc: 1.0000 - val_loss: 3.0601 - val_acc: 0.5000\n",
      "Epoch 99/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 5.2301e-04 - acc: 1.0000\n",
      "Epoch 99: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 5.2018e-04 - acc: 1.0000 - val_loss: 3.0186 - val_acc: 0.5000\n",
      "Epoch 100/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 5.1144e-04 - acc: 1.0000\n",
      "Epoch 100: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 5.0198e-04 - acc: 1.0000 - val_loss: 3.1303 - val_acc: 0.5000\n",
      "Epoch 101/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 5.2011e-04 - acc: 1.0000\n",
      "Epoch 101: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 5.0300e-04 - acc: 1.0000 - val_loss: 3.1430 - val_acc: 0.5000\n",
      "Epoch 102/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 4.9878e-04 - acc: 1.0000\n",
      "Epoch 102: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 4.8562e-04 - acc: 1.0000 - val_loss: 3.0510 - val_acc: 0.5000\n",
      "Epoch 103/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 4.7954e-04 - acc: 1.0000\n",
      "Epoch 103: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 4.7217e-04 - acc: 1.0000 - val_loss: 3.1676 - val_acc: 0.5000\n",
      "Epoch 104/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 4.7721e-04 - acc: 1.0000\n",
      "Epoch 104: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 4.6205e-04 - acc: 1.0000 - val_loss: 3.1961 - val_acc: 0.5000\n",
      "Epoch 105/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 4.4893e-04 - acc: 1.0000\n",
      "Epoch 105: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 4.5296e-04 - acc: 1.0000 - val_loss: 3.0505 - val_acc: 0.5000\n",
      "Epoch 106/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 4.5134e-04 - acc: 1.0000\n",
      "Epoch 106: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 4.3853e-04 - acc: 1.0000 - val_loss: 3.2600 - val_acc: 0.5000\n",
      "Epoch 107/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 4.3605e-04 - acc: 1.0000\n",
      "Epoch 107: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 4.2849e-04 - acc: 1.0000 - val_loss: 3.1453 - val_acc: 0.5000\n",
      "Epoch 108/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 4.0551e-04 - acc: 1.0000\n",
      "Epoch 108: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 4.2015e-04 - acc: 1.0000 - val_loss: 3.1521 - val_acc: 0.5000\n",
      "Epoch 109/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 4.3020e-04 - acc: 1.0000\n",
      "Epoch 109: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 4.0802e-04 - acc: 1.0000 - val_loss: 3.1545 - val_acc: 0.5000\n",
      "Epoch 110/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 3.7416e-04 - acc: 1.0000\n",
      "Epoch 110: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 4.0274e-04 - acc: 1.0000 - val_loss: 3.2231 - val_acc: 0.5000\n",
      "Epoch 111/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 3.5873e-04 - acc: 1.0000\n",
      "Epoch 111: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.9379e-04 - acc: 1.0000 - val_loss: 3.1679 - val_acc: 0.5000\n",
      "Epoch 112/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.8714e-04 - acc: 1.0000\n",
      "Epoch 112: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.8382e-04 - acc: 1.0000 - val_loss: 3.2532 - val_acc: 0.5000\n",
      "Epoch 113/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 3.5792e-04 - acc: 1.0000\n",
      "Epoch 113: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.7710e-04 - acc: 1.0000 - val_loss: 3.1570 - val_acc: 0.5000\n",
      "Epoch 114/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 3.6208e-04 - acc: 1.0000\n",
      "Epoch 114: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.6966e-04 - acc: 1.0000 - val_loss: 3.2205 - val_acc: 0.5000\n",
      "Epoch 115/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 3.7680e-04 - acc: 1.0000\n",
      "Epoch 115: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.6503e-04 - acc: 1.0000 - val_loss: 3.1785 - val_acc: 0.5000\n",
      "Epoch 116/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 3.5324e-04 - acc: 1.0000\n",
      "Epoch 116: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 3.5311e-04 - acc: 1.0000 - val_loss: 3.1886 - val_acc: 0.5000\n",
      "Epoch 117/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 3.5038e-04 - acc: 1.0000\n",
      "Epoch 117: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.4366e-04 - acc: 1.0000 - val_loss: 3.2800 - val_acc: 0.5000\n",
      "Epoch 118/150\n",
      "20/39 [==============>...............] - ETA: 0s - loss: 3.0288e-04 - acc: 1.0000\n",
      "Epoch 118: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.3712e-04 - acc: 1.0000 - val_loss: 3.2437 - val_acc: 0.5000\n",
      "Epoch 119/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 3.2131e-04 - acc: 1.0000\n",
      "Epoch 119: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.3139e-04 - acc: 1.0000 - val_loss: 3.2987 - val_acc: 0.5000\n",
      "Epoch 120/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 3.3573e-04 - acc: 1.0000\n",
      "Epoch 120: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.3182e-04 - acc: 1.0000 - val_loss: 3.1051 - val_acc: 0.5000\n",
      "Epoch 121/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 3.0551e-04 - acc: 1.0000\n",
      "Epoch 121: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.1651e-04 - acc: 1.0000 - val_loss: 3.4034 - val_acc: 0.5000\n",
      "Epoch 122/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 3.1172e-04 - acc: 1.0000\n",
      "Epoch 122: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.1010e-04 - acc: 1.0000 - val_loss: 3.2459 - val_acc: 0.5000\n",
      "Epoch 123/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 2.9075e-04 - acc: 1.0000\n",
      "Epoch 123: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 3.0524e-04 - acc: 1.0000 - val_loss: 3.4040 - val_acc: 0.5000\n",
      "Epoch 124/150\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 2.8444e-04 - acc: 1.0000\n",
      "Epoch 124: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 2.9449e-04 - acc: 1.0000 - val_loss: 3.3033 - val_acc: 0.5000\n",
      "Epoch 125/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 2.8445e-04 - acc: 1.0000\n",
      "Epoch 125: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.9039e-04 - acc: 1.0000 - val_loss: 3.4316 - val_acc: 0.5000\n",
      "Epoch 126/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 2.9572e-04 - acc: 1.0000\n",
      "Epoch 126: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.8856e-04 - acc: 1.0000 - val_loss: 3.4684 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 2.8811e-04 - acc: 1.0000\n",
      "Epoch 127: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.8507e-04 - acc: 1.0000 - val_loss: 3.2148 - val_acc: 0.5000\n",
      "Epoch 128/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 2.5761e-04 - acc: 1.0000\n",
      "Epoch 128: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.7189e-04 - acc: 1.0000 - val_loss: 3.4020 - val_acc: 0.5000\n",
      "Epoch 129/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 2.7775e-04 - acc: 1.0000\n",
      "Epoch 129: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 2.6968e-04 - acc: 1.0000 - val_loss: 3.3224 - val_acc: 0.5000\n",
      "Epoch 130/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 2.6377e-04 - acc: 1.0000\n",
      "Epoch 130: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.6166e-04 - acc: 1.0000 - val_loss: 3.4321 - val_acc: 0.5000\n",
      "Epoch 131/150\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 2.7055e-04 - acc: 1.0000\n",
      "Epoch 131: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 2.6228e-04 - acc: 1.0000 - val_loss: 3.4895 - val_acc: 0.5000\n",
      "Epoch 132/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 2.5106e-04 - acc: 1.0000\n",
      "Epoch 132: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 2.5068e-04 - acc: 1.0000 - val_loss: 3.3459 - val_acc: 0.5000\n",
      "Epoch 133/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 2.5385e-04 - acc: 1.0000\n",
      "Epoch 133: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.4467e-04 - acc: 1.0000 - val_loss: 3.3135 - val_acc: 0.5000\n",
      "Epoch 134/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 2.3931e-04 - acc: 1.0000\n",
      "Epoch 134: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.3821e-04 - acc: 1.0000 - val_loss: 3.4280 - val_acc: 0.5000\n",
      "Epoch 135/150\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 1.8467e-04 - acc: 1.0000\n",
      "Epoch 135: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 2.3941e-04 - acc: 1.0000 - val_loss: 3.4196 - val_acc: 0.5000\n",
      "Epoch 136/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 2.3233e-04 - acc: 1.0000\n",
      "Epoch 136: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.3233e-04 - acc: 1.0000 - val_loss: 3.4196 - val_acc: 0.5000\n",
      "Epoch 137/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 2.2887e-04 - acc: 1.0000\n",
      "Epoch 137: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 2.2201e-04 - acc: 1.0000 - val_loss: 3.4814 - val_acc: 0.5000\n",
      "Epoch 138/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 2.3069e-04 - acc: 1.0000\n",
      "Epoch 138: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.2815e-04 - acc: 1.0000 - val_loss: 3.3519 - val_acc: 0.5000\n",
      "Epoch 139/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 2.2362e-04 - acc: 1.0000\n",
      "Epoch 139: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.1520e-04 - acc: 1.0000 - val_loss: 3.5281 - val_acc: 0.5000\n",
      "Epoch 140/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 2.1138e-04 - acc: 1.0000\n",
      "Epoch 140: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.1138e-04 - acc: 1.0000 - val_loss: 3.3821 - val_acc: 0.5000\n",
      "Epoch 141/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 1.9549e-04 - acc: 1.0000\n",
      "Epoch 141: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.0373e-04 - acc: 1.0000 - val_loss: 3.5660 - val_acc: 0.5000\n",
      "Epoch 142/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 2.0903e-04 - acc: 1.0000\n",
      "Epoch 142: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 2.0740e-04 - acc: 1.0000 - val_loss: 3.4147 - val_acc: 0.5000\n",
      "Epoch 143/150\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.9840e-04 - acc: 1.0000\n",
      "Epoch 143: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.9805e-04 - acc: 1.0000 - val_loss: 3.4894 - val_acc: 0.5000\n",
      "Epoch 144/150\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 2.0689e-04 - acc: 1.0000\n",
      "Epoch 144: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1.9822e-04 - acc: 1.0000 - val_loss: 3.3988 - val_acc: 0.5000\n",
      "Epoch 145/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 1.8578e-04 - acc: 1.0000\n",
      "Epoch 145: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.9516e-04 - acc: 1.0000 - val_loss: 3.4872 - val_acc: 0.5000\n",
      "Epoch 146/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 1.8839e-04 - acc: 1.0000\n",
      "Epoch 146: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.8562e-04 - acc: 1.0000 - val_loss: 3.5663 - val_acc: 0.5000\n",
      "Epoch 147/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 1.8917e-04 - acc: 1.0000\n",
      "Epoch 147: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.8319e-04 - acc: 1.0000 - val_loss: 3.5558 - val_acc: 0.5000\n",
      "Epoch 148/150\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 1.8510e-04 - acc: 1.0000\n",
      "Epoch 148: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.8155e-04 - acc: 1.0000 - val_loss: 3.3773 - val_acc: 0.5000\n",
      "Epoch 149/150\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 1.8367e-04 - acc: 1.0000\n",
      "Epoch 149: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.8027e-04 - acc: 1.0000 - val_loss: 3.6006 - val_acc: 0.5000\n",
      "Epoch 150/150\n",
      "19/39 [=============>................] - ETA: 0s - loss: 1.8682e-04 - acc: 1.0000\n",
      "Epoch 150: val_loss did not improve from 0.84667\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.7331e-04 - acc: 1.0000 - val_loss: 3.4482 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[checkpoint],\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9023f4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49051e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "def prediction(img_path):\n",
    "    org_img = image.load_img(img_path)\n",
    "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "    img_tensor = image.img_to_array(img)  \n",
    "    img_tensor /= 255.  \n",
    "    plt.imshow(org_img)                           \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Extract features\n",
    "    features = conv_base.predict(img_tensor.reshape(1,img_width, img_height, 3))\n",
    "\n",
    "    # Make prediction\n",
    "    try:\n",
    "        prediction = model.predict(features)\n",
    "    except:\n",
    "        prediction = model.predict(features.reshape(1, 7*7*1024))\n",
    "        \n",
    "    classes = [\"covid\",\"noncovid\"]\n",
    "    print(\"I see...\"+str(classes[np.argmax(np.array(prediction[0]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d324427",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "318bcbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f03ee8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(prediction, axis=1)\n",
    "# label\n",
    "validation_labels = np.argmax(validation_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a81e2426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,) (16,)\n"
     ]
    }
   ],
   "source": [
    "print(validation_labels.shape, pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "513d3920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Covid       0.00      0.00      0.00         8\n",
      "    NonCovid       0.50      1.00      0.67         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_labels, pred, target_names = ['Covid','NonCovid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7041c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
